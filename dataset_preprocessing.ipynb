{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d5f368-b524-4dc8-915d-83b5b68dd94b",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25947320",
   "metadata": {},
   "source": [
    "### In this process, we convert the annotations from the VisDrone dataset format to the YOLO annotation format.\n",
    "\n",
    "VisDrone Annotation Format\n",
    "The VisDrone dataset provides annotations in a specific format, where each object in an image is represented by a line with the following fields:\n",
    "\n",
    "\n",
    "- [x_min, y_min, width, height, class_id, difficult, truncated, occluded]\n",
    "\n",
    "    - **x_min, y_min**: The coordinates of the top-left corner of the bounding box.\n",
    "    - **width, height**: The width and height of the bounding box.\n",
    "    - **class_id**: The numerical identifier for the object class.\n",
    "    - **difficult**: A flag indicating if the object is difficult to detect.\n",
    "    - **truncated**: A flag indicating if the object is truncated (partially visible).\n",
    "    - **occluded**: A flag indicating if the object is occluded (partially blocked by another object).\n",
    "\n",
    "YOLO Annotation Format\n",
    "In contrast, the YOLO annotation format represents bounding boxes relative to the image size, with normalized values between 0 and 1. The format for each object is:\n",
    "\n",
    "- [class_id, x_center, y_center, width, height]\n",
    "\n",
    "    - **class_id**: The numerical identifier for the object class.\n",
    "    - **x_center, y_center**: The normalized coordinates of the bounding box center.\n",
    "    - **width, height**: The normalized width and height of the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ed6152-42e5-40e9-a45b-4c8454bc2236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting C:\\Users\\juank\\AI Projects\\VisDrone\\dataset\\VisDrone2019-DET-train: 6471it [01:23, 77.21it/s] \n",
      "Converting C:\\Users\\juank\\AI Projects\\VisDrone\\dataset\\VisDrone2019-DET-val: 548it [00:07, 71.03it/s] \n",
      "Converting C:\\Users\\juank\\AI Projects\\VisDrone\\dataset\\VisDrone2019-DET-test-dev: 1610it [00:18, 86.01it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from ultralytics.utils.downloads import download\n",
    "\n",
    "def visdrone2yolo(directory):\n",
    "    def convert_box(size, box):\n",
    "        # Convert VisDrone box to YOLO xywh box\n",
    "        dw = 1. / size[0]\n",
    "        dh = 1. / size[1]\n",
    "        return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh\n",
    "\n",
    "    (directory / 'labels').mkdir(parents=True, exist_ok=True)  # create labels directory\n",
    "    pbar = tqdm((directory / 'annotations').glob('*.txt'), desc=f'Converting {directory}')\n",
    "    for f in pbar:\n",
    "        img_size = Image.open((directory / 'images' / f.name).with_suffix('.jpg')).size\n",
    "        lines = []\n",
    "        with open(f, 'r') as file:  # read annotation.txt\n",
    "            for row in [x.split(',') for x in file.read().strip().splitlines()]:\n",
    "                if row[4] == '0':  # VisDrone 'ignored regions' class 0\n",
    "                    continue\n",
    "                cls = int(row[5]) - 1\n",
    "                box = convert_box(img_size, tuple(map(int, row[:4])))\n",
    "                lines.append(f\"{cls} {' '.join(f'{x:.6f}' for x in box)}\\n\")\n",
    "                with open(str(f).replace(f'{os.sep}annotations{os.sep}', f'{os.sep}labels{os.sep}'), 'w') as fl:\n",
    "                    fl.writelines(lines)  # write label.txt\n",
    "\n",
    "# Define the directory containing your annotations\n",
    "directory = Path(\"C:/Users/juank/AI Projects/VisDrone/dataset\")  # root dataset dir\n",
    "\n",
    "# Convert VisDrone annotations to YOLO labels for the following datasets\n",
    "for d in ['VisDrone2019-DET-train', 'VisDrone2019-DET-val', 'VisDrone2019-DET-test-dev']:\n",
    "    visdrone2yolo(directory / d)  # convert VisDrone annotations to YOLO labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1262a3-5b72-4e02-9d63-3e56dac19ee9",
   "metadata": {},
   "source": [
    "# Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708841c2-447d-4ffb-8db9-5080a3b6cb24",
   "metadata": {},
   "source": [
    "After converting the annotations from the VISDRONE format in the \"annotations\" folder to the YOLO format in the \"labels\" folder, the \"annotations\" folder is deleted to prevent any issues during model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
